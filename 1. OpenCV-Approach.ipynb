{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# People Counter\n",
    "## Goal\n",
    "Count the number of unique people wihtin a video.\n",
    "\n",
    "## Using OpenCV (w/o ML/DL)\n",
    "### Testing a Single Face Detection with Webcam Video Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this OpenCV-approach we will use Viola & Jonesâ€™ (2001) Haar Cascade Classifier, as this is also implemented in OpenCV.  \n",
    "Good Read ðŸ“„ https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf\n",
    "\n",
    "OpenCV provides various classifier: https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "\n",
    "For our use case we focus on the four provided `*frontface*` cascades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Videos\n",
    "If computational time is too high, reduce video files using FFmpeg:  \n",
    "NB This will have an impact on the face detection accuracy and should only be used in dev.  \n",
    "Scale down to 540p or 720p and 25fps (apply for video1 and video3):  \n",
    "`ffmpeg -i video1.mp4 -filter:v \"scale=-1:540, fps=fps=25\" -c:a copy video1s.mp4`  \n",
    "`ffmpeg -i video3.mp4 -filter:v \"scale=-1:720, fps=fps=25\" -c:a copy video3s.mp4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the defaul facial haar cascade\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascades/haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define detect face function\n",
    "# we will use this to pipe every frame of video stream (either webcam or existing file) in this function\n",
    "def detect_face(img):\n",
    "    \n",
    "    face_img = img.copy()\n",
    "      \n",
    "    # use face_cascade with detectMultiScale\n",
    "    # ðŸ’¡ detectMultiScale retruns the tuple-shaped rectangle coords (x,y,w,h)\n",
    "    face_rectangle_coords = face_cascade.detectMultiScale(face_img)\n",
    "\n",
    "    # draw a rectangle on-top of the current frame using the face_rectangle_coords\n",
    "    for (x, y, w, h) in face_rectangle_coords: \n",
    "        cv2.rectangle(face_img, (x, y), (x + w, y + h), (255, 255, 255), 10) \n",
    "\n",
    "    return face_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open webcam stream (define input file with: cv2.VideoCapture(\"path/to/file.mp4\"))\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "# Iterate over the stream\n",
    "while True: \n",
    "\n",
    "    # ret indicates if the previous frame (i.e., frame) was valid (true false)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # pipe the current frame in detect faces\n",
    "    frame = detect_face(frame)\n",
    "    \n",
    "    # imshow(Windows Title, frame)\n",
    "    cv2.imshow('Video Face Detection', frame) \n",
    " \n",
    "    # Define escape key (i.e., 27) to break the stream\n",
    "    c = cv2.waitKey(1) \n",
    "    if c == 27: \n",
    "        break \n",
    "    \n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: Display output gif, including detection performance, occlusion behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§® Counting Strategy\n",
    "- Count the number of detcted rectangles (i.e., faces) within a frame\n",
    "\n",
    "Todo: rework display to include the number of rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a Face Detection within Video File\n",
    "- No occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('videos/video3.mp4') \n",
    "\n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    frame = detect_face(frame)\n",
    "    cv2.imshow('Video Face Detection', frame) \n",
    " \n",
    "    c = cv2.waitKey(1) \n",
    "    if c == 27: \n",
    "        break \n",
    "    \n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "- Viola-Jones\n",
    "- no modification\n",
    "- haarcascade_frontalface_default\n",
    "\n",
    "![bild](img/frontalface_default.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo modify parameters and use other haar classifiers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
